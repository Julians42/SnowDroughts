{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Computes SPEAR-MED Z-Scores\n",
    "We re-compute z-scores for all variables of interest for SPEAR-MED ensemble members. We standardize the format so that all calculations of historical and future scenario data is formatted identically. Embarrassingly parallel is used save time as ensemble members can be treated independently."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from imports import *\n",
    "from netCDF4 import Dataset # for saving netcdfs \n",
    "from cartopy.feature import ShapelyFeature # for plotting HUC2 regions\n",
    "from cartopy.io.shapereader import Reader\n",
    "from joblib import Parallel, delayed"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Functions for computing historical zscores\n",
    "def is_winter(month):\n",
    "    return (month <=4) | (month >=10)\n",
    "\n",
    "def ZSCORES_historical(hist_ar, lat, lon):\n",
    "    \"\"\"Crank ZSCORES in numpy\"\"\"\n",
    "    # get slices\n",
    "    hist_slice = hist_ar[:, lat, lon]\n",
    "    # get empirical distribution based on historical\n",
    "    dist = ECDF(hist_slice, side='right')\n",
    "    # rank historical snowfall\n",
    "    INDEX = dist(hist_slice)\n",
    "    # clean 0s and 1s - which result in infs under inverse normal transformation \n",
    "    try:\n",
    "        min_value, max_value = dist.y[1], dist.y[-2]  # base thresholds on historical distribution\n",
    "        # clean up infs (0s and 1s)\n",
    "        INDEX = np.where(INDEX < min_value, min_value, INDEX)\n",
    "        INDEX = np.where(INDEX > max_value, max_value, INDEX)\n",
    "    except ValueError:\n",
    "        pass\n",
    "    \n",
    "    # return indices as z-scores\n",
    "    return norm.ppf(INDEX)\n",
    "\n",
    "def hist_monthly_ZSCORES(hist_ar):\n",
    "    \"\"\"Computes Zscores over all gridcells\"\"\"\n",
    "    # copy array for saving data\n",
    "    future_ZSCORES = hist_ar.copy()\n",
    "    # get dims\n",
    "    nlats = hist_ar.shape[1]\n",
    "    nlons = hist_ar.shape[2]\n",
    "    \n",
    "    # iterate through array\n",
    "    for lat in range(nlats):\n",
    "        for lon in range(nlons):\n",
    "            \n",
    "            # compute gridpoint level SWEI\n",
    "            ZSCORES = ZSCORES_historical(hist_ar, lat, lon)\n",
    "            future_ZSCORES[:, lat, lon] = ZSCORES # add to array\n",
    "            \n",
    "    return future_ZSCORES\n",
    "\n",
    "def historical_zscores(hist_ens, variable, path_var):\n",
    "    \"\"\"Takes files and computes SWEI for historical dataset. \"\"\"\n",
    "    \n",
    "    # constants - easier if wrapped in function \n",
    "    lat_new = np.arange(32, 52, 0.5)\n",
    "    lon_new = np.arange(235, 255, 0.5)\n",
    "    \n",
    "    # load historical ds\n",
    "    historical = xr.open_mfdataset(hist_ens)\n",
    "    \n",
    "    # process to correct grid-cells\n",
    "    historical = historical.reindex(lat=lat_new, lon=lon_new, method=\"nearest\")\n",
    "    \n",
    "    # cycle through months of year\n",
    "    months = []\n",
    "    for month in range(1,13):\n",
    "        \n",
    "        # extract snow values and save to numpy for faster computation\n",
    "        hst = historical.sel(time=historical[\"time.month\"]==month)\n",
    "        \n",
    "        hist_ar  = np.array(hst[variable])\n",
    "        \n",
    "        # process to Z-scores values\n",
    "        ZSCORES  = hist_monthly_ZSCORES(hist_ar)\n",
    "        \n",
    "        # format array as month \n",
    "        month_xr = xr.Dataset(\n",
    "                        data_vars=dict(\n",
    "                            zscores=(['time', 'lat','lon'], ZSCORES)),\n",
    "\n",
    "                        coords=dict(\n",
    "                            lat=(['lat'], lat_new),\n",
    "                            lon =(['lon'], lon_new),\n",
    "                            time= hst.time))\n",
    "        \n",
    "        # append to months array\n",
    "        months.append(month_xr)\n",
    "        \n",
    "    # concatenate arrays and return xarray dataset sorted by time\n",
    "    ens_member_zscores = xr.concat(months, dim=\"time\").sortby('time')\n",
    "    \n",
    "    # get ensemble number and create directory if needed to save files\n",
    "    index = hist_ens.split(\"/\")[4].split(\"_\")[-1]\n",
    "    fpath = f\"/work/Julian.Schmitt/data/zscores/{path_var}/hist/hist_monthly_ens_{index}.nc\"\n",
    "    \n",
    "    if not os.path.exists(os.path.dirname(fpath)):\n",
    "        os.makedirs(os.path.dirname(fpath))\n",
    "    \n",
    "    # save to netcdf and return dataset \n",
    "    ens_member_zscores.to_netcdf(fpath)\n",
    "    return ens_member_zscores"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# get filenames \n",
    "snow_historical   = glob(\"/decp/SPEAR_MED/SPEAR_c192_o1_Hist_AllForc_IC1921_K50/\"\n",
    "                         \"pp_ens_*/land/ts/monthly/94yr/land.192101-201412.snow.nc\")\n",
    "precip_historical = glob(\"/decp/SPEAR_MED/SPEAR_c192_o1_Hist_AllForc_IC1921_K50/\"\n",
    "                         \"pp_ens_*/atmos/ts/monthly/94yr/atmos.192101-201412.precip.nc\")\n",
    "temp_historical   = glob(\"/decp/SPEAR_MED/SPEAR_c192_o1_Hist_AllForc_IC1921_K50/pp_ens_*/\"\n",
    "                         \"atmos/ts/monthly/94yr/atmos.192101-201412.t_ref.nc\")\n",
    "tmin_historical   = glob(\"/decp/SPEAR_MED/SPEAR_c192_o1_Hist_AllForc_IC1921_K50/pp_ens_*/atmos/\"\n",
    "                         \"ts/monthly/94yr/atmos.192101-201412.t_ref_min.nc\")\n",
    "tmax_historical   = glob(\"/decp/SPEAR_MED/SPEAR_c192_o1_Hist_AllForc_IC1921_K50/pp_ens_*/atmos/\"\n",
    "                         \"ts/monthly/94yr/atmos.192101-201412.t_ref_max.nc\")\n",
    "\n",
    "# SSP585 - max forcing \n",
    "snow_future   = glob(\"/decp/SPEAR_MED/SPEAR_c192_o1_Scen_SSP585_IC2011_K50/\"\n",
    "                     \"pp_ens_*/land/ts/monthly/86yr/land.201501-210012.snow.nc\")\n",
    "precip_future = glob(\"/decp/SPEAR_MED/SPEAR_c192_o1_Scen_SSP585_IC2011_K50/pp_ens_*/atmos/ts\"\n",
    "                     \"/monthly/86yr/atmos.201501-210012.precip.nc\")\n",
    "temp_future   = glob(\"/decp/SPEAR_MED/SPEAR_c192_o1_Scen_SSP585_IC2011_K50/pp_ens_*/atmos/ts\"\n",
    "                     \"/monthly/86yr/atmos.201501-210012.t_ref.nc\")\n",
    "tmax_future   = glob(\"/decp/SPEAR_MED/SPEAR_c192_o1_Scen_SSP585_IC2011_K50/pp_ens_*/atmos/ts\"\n",
    "                     \"/monthly/86yr/atmos.201501-210012.t_ref_max.nc\")\n",
    "tmin_future   = glob(\"/decp/SPEAR_MED/SPEAR_c192_o1_Scen_SSP585_IC2011_K50/pp_ens_*/atmos/ts\"\n",
    "                     \"/monthly/86yr/atmos.201501-210012.t_ref_min.nc\")\n",
    "\n",
    "# SSP245 - medium forcing\n",
    "snow_future245   = glob(\"/decp/SPEAR_MED/SPEAR_c192_o1_Scen_SSP245_IC2011_K50/\"\n",
    "                     \"pp_ens_*/land/ts/monthly/86yr/land.201501-210012.snow.nc\")\n",
    "precip_future245 = glob(\"/decp/SPEAR_MED/SPEAR_c192_o1_Scen_SSP245_IC2011_K50/pp_ens_*/atmos/ts\"\n",
    "                     \"/monthly/86yr/atmos.201501-210012.precip.nc\")\n",
    "temp_future245   = glob(\"/decp/SPEAR_MED/SPEAR_c192_o1_Scen_SSP245_IC2011_K50/pp_ens_*/atmos/ts\"\n",
    "                     \"/monthly/86yr/atmos.201501-210012.t_ref.nc\")\n",
    "tmax_future245   = glob(\"/decp/SPEAR_MED/SPEAR_c192_o1_Scen_SSP245_IC2011_K50/pp_ens_*/atmos/ts\"\n",
    "                     \"/monthly/86yr/atmos.201501-210012.t_ref_max.nc\")\n",
    "tmin_future245   = glob(\"/decp/SPEAR_MED/SPEAR_c192_o1_Scen_SSP245_IC2011_K50/pp_ens_*/atmos/ts\"\n",
    "                     \"/monthly/86yr/atmos.201501-210012.t_ref_min.nc\")\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "%%time\n",
    "# compute zscores for historical datasets\n",
    "ncores = os.cpu_count()\n",
    "hist_snow_ds   = Parallel(n_jobs=ncores)(delayed(historical_zscores)(snow_historical[i], \"snow\", \"snow\") \n",
    "                                                                                    for i in range(30))\n",
    "print(\"Computed Snow ZScores\")\n",
    "hist_precip_ds = Parallel(n_jobs=ncores)(delayed(historical_zscores)(precip_historical[i], \"precip\", \"precip\") \n",
    "                                                                                    for i in range(30))\n",
    "print(\"Computed Precip ZScores\")\n",
    "hist_temp_ds   = Parallel(n_jobs=ncores)(delayed(historical_zscores)(temp_historical[i], \"t_ref\", \"temp\") \n",
    "                                                                                    for i in range(30))\n",
    "print(\"Computed Temp ZScores\")\n",
    "hist_tmin_ds   = Parallel(n_jobs=ncores)(delayed(historical_zscores)(tmin_historical[i], \"t_ref_min\", \"tmin\") \n",
    "                                                                                    for i in range(30))\n",
    "print(\"Computed Tmin ZScores\")\n",
    "hist_tmax_ds   = Parallel(n_jobs=ncores)(delayed(historical_zscores)(tmax_historical[i], \"t_ref_max\", \"tmax\") \n",
    "                                                                                    for i in range(30))\n",
    "print(\"Computed Tmax Zscores\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Computed Snow ZScores\n",
      "Computed Precip ZScores\n",
      "Computed Temp ZScores\n",
      "Computed Tmin ZScores\n",
      "Computed Tmax Zscores\n",
      "CPU times: user 2.35 s, sys: 1.08 s, total: 3.43 s\n",
      "Wall time: 8min 53s\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Compute ZScores for future conditions\n",
    "We base the future zscores off of the entire historical record. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "def ZSCORES_from_historical(hist_ar, future_ar, lat, lon):\n",
    "    \"\"\"Compute ZSCORES in numpy for future datasets based on historical\"\"\"\n",
    "    # get slices\n",
    "    hist_slice = hist_ar[:, lat, lon]\n",
    "    future_slice = future_ar[:, lat, lon]\n",
    "    # get empirical distribution based on historical\n",
    "    dist = ECDF(hist_slice, side='right')\n",
    "    # rank values for future snowfall\n",
    "    INDEX = dist(future_slice)\n",
    "    # clean 0s and 1s - which result in infs under inverse normal transformation \n",
    "    try:\n",
    "        min_value, max_value = dist.y[1], dist.y[-2]  # base thresholds on historical distribution - eg remove infs \n",
    "        INDEX = np.where(INDEX < min_value, min_value, INDEX)\n",
    "        INDEX = np.where(INDEX > max_value, max_value, INDEX)\n",
    "    except ValueError:\n",
    "        pass\n",
    "    \n",
    "    # return indices as z-scores\n",
    "    return norm.ppf(INDEX)\n",
    "\n",
    "def month_ZSCORES(hist_ar, future_ar):\n",
    "    # copy array for saving data\n",
    "    future_ZSCORES = future_ar.copy()\n",
    "    # get dims\n",
    "    nlats = hist_ar.shape[1]\n",
    "    nlons = hist_ar.shape[2]\n",
    "    # iterate through array\n",
    "    for lat in range(nlats):\n",
    "        for lon in range(nlons):\n",
    "            # compute gridpoint level SWEI\n",
    "            ZSCORES = ZSCORES_from_historical(hist_ar, future_ar, lat, lon)\n",
    "            # add to array\n",
    "            future_ZSCORES[:, lat, lon] = ZSCORES\n",
    "    return future_ZSCORES\n",
    "\n",
    "def future_zscores(hist_ens, ssp_ens, variable, path_var):\n",
    "    \"\"\"Takes files and computes SWEI for future dataset. \"\"\"\n",
    "    # constants - easier if wrapped in function \n",
    "    lat_new = np.arange(32, 52, 0.5)\n",
    "    lon_new = np.arange(235, 255, 0.5)\n",
    "    \n",
    "    # load files\n",
    "    historical = xr.open_mfdataset(hist_ens)\n",
    "    future     = xr.open_mfdataset(ssp_ens)\n",
    "    \n",
    "    # process to correct grid-cells\n",
    "    historical = historical.reindex(lat=lat_new, lon=lon_new, method=\"nearest\")\n",
    "    future     = future.reindex(lat=lat_new, lon=lon_new, method=\"nearest\")\n",
    "    \n",
    "    # cycle through months of year\n",
    "    months = []\n",
    "    for month in range(1,13):\n",
    "        \n",
    "        # extract snow values and save to numpy for faster computation\n",
    "        hst = historical.sel(time=historical[\"time.month\"]==month)\n",
    "        ftr = future.sel(time=future['time.month']==month)\n",
    "        \n",
    "        hist_ar   = np.array(hst[variable])\n",
    "        future_ar = np.array(ftr[variable])\n",
    "        \n",
    "        # process to Z-scores values\n",
    "        ZSCORES = month_ZSCORES(hist_ar, future_ar)\n",
    "        \n",
    "        # format array as month and transform to xarray dataset object\n",
    "        month_xr = xr.Dataset(\n",
    "                        data_vars=dict(\n",
    "                            zscores=(['time', 'lat','lon'], ZSCORES)),\n",
    "\n",
    "                        coords=dict(\n",
    "                            lat=(['lat'], lat_new),\n",
    "                            lon =(['lon'], lon_new),\n",
    "                            time= ftr.time))\n",
    "        \n",
    "        # append to months array\n",
    "        months.append(month_xr)\n",
    "        \n",
    "    # concatenate arrays and return xarray dataset sorted by time\n",
    "    ens_member_zscores = xr.concat(months, dim=\"time\").sortby('time')\n",
    "    \n",
    "    # get ensemble number and create directory if needed to save files\n",
    "    index = hist_ens.split(\"/\")[4].split(\"_\")[-1]\n",
    "    fpath = f\"/work/Julian.Schmitt/data/zscores/{path_var}i/future245/future_monthly_ens_{index}.nc\"\n",
    "    \n",
    "    if not os.path.exists(os.path.dirname(fpath)):\n",
    "        os.makedirs(os.path.dirname(fpath))\n",
    "    \n",
    "    # save to netcdf and return dataset \n",
    "    ens_member_zscores.to_netcdf(fpath)\n",
    "    return ens_member_zscores"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "# compute zscores for future values\n",
    "ncores = os.cpu_count() # use all available cores\n",
    "future_snow_ds   = Parallel(n_jobs=ncores)(delayed(future_zscores)(snow_historical[i], snow_future[i], \"snow\", \"snow\") \n",
    "                                                                                    for i in range(30))\n",
    "print(\"Computed Snow ZScores\")\n",
    "future_precip_ds = Parallel(n_jobs=ncores)(delayed(future_zscores)(precip_historical[i], precip_future[i], \"precip\", \"precip\") \n",
    "                                                                                    for i in range(30))\n",
    "print(\"Computed Precip ZScores\")\n",
    "future_temp_ds   = Parallel(n_jobs=ncores)(delayed(future_zscores)(temp_historical[i], temp_future[i], \"t_ref\", \"temp\") \n",
    "                                                                                    for i in range(30))\n",
    "print(\"Computed Temp ZScores\")\n",
    "future_tmin_ds   = Parallel(n_jobs=ncores)(delayed(future_zscores)(tmin_historical[i], tmin_future[i], \"t_ref_min\", \"tmin\") \n",
    "                                                                                    for i in range(30))\n",
    "print(\"Computed Tmin ZScores\")\n",
    "future_tmax_ds   = Parallel(n_jobs=ncores)(delayed(future_zscores)(tmax_historical[i], tmax_future[i], \"t_ref_max\", \"tmax\") \n",
    "                                                                                    for i in range(30))\n",
    "print(\"Computed Tmax ZScores\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Computed Snow ZScores\n",
      "Computed Precip ZScores\n",
      "Computed Temp ZScores\n",
      "Computed Tmin ZScores\n",
      "Computed Tmax ZScores\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Compute zscores for medium forcing levels\n",
    "ncores = os.cpu_count() # use all available cores\n",
    "future_snow_ds245   = Parallel(n_jobs=ncores)(delayed(future_zscores)(snow_historical[i], snow_future245[i], \"snow\", \"snow\") \n",
    "                                                                                    for i in range(30))\n",
    "print(\"Computed Snow ZScores\")\n",
    "future_precip_ds245 = Parallel(n_jobs=ncores)(delayed(future_zscores)(precip_historical[i], precip_future245[i], \"precip\", \"precip\") \n",
    "                                                                                    for i in range(30))\n",
    "print(\"Computed Precip ZScores\")\n",
    "future_temp_ds245   = Parallel(n_jobs=ncores)(delayed(future_zscores)(temp_historical[i], temp_future245[i], \"t_ref\", \"temp\") \n",
    "                                                                                    for i in range(30))\n",
    "print(\"Computed Temp ZScores\")\n",
    "future_tmin_ds245   = Parallel(n_jobs=ncores)(delayed(future_zscores)(tmin_historical[i], tmin_future245[i], \"t_ref_min\", \"tmin\") \n",
    "                                                                                    for i in range(30))\n",
    "print(\"Computed Tmin ZScores\")\n",
    "future_tmax_ds245   = Parallel(n_jobs=ncores)(delayed(future_zscores)(tmax_historical[i], tmax_future245[i], \"t_ref_max\", \"tmax\") \n",
    "                                                                                    for i in range(30))\n",
    "print(\"Computed Tmax ZScores\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Computed Snow ZScores\n",
      "Computed Precip ZScores\n",
      "Computed Temp ZScores\n",
      "Computed Tmin ZScores\n",
      "Computed Tmax ZScores\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}